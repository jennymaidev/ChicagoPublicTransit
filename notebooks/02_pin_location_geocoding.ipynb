{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b87b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "\n",
    "DATA_DIR = '../data/raw/'\n",
    "INTERIM_DIR = '../data/interim/'\n",
    "CTA_FILE_PATH = os.path.join(DATA_DIR, 'cta_l_stops.geojson')\n",
    "os.makedirs(INTERIM_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cta = gpd.read_file(CTA_FILE_PATH)\n",
    "gdf_cta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91abbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial CTA Station Columns:\", gdf_cta.columns.tolist())\n",
    "gdf_cta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47367457",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_column = 'longname' \n",
    "lines_column = 'legend'\n",
    "gdf_cta['Line_Colors'] = gdf_cta[lines_column].str.replace(' Line', '', regex=False).str.replace(', ', ',', regex=False)\n",
    "gdf_cta[[name_column, lines_column, 'Line_Colors', 'geometry']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a472361",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total unique station names: {gdf_cta[name_column].nunique()}\")\n",
    "print(f\"Total rows in DataFrame: {len(gdf_cta)}\")\n",
    "print(\"Top 5 unique Line_Colors combinations:\")\n",
    "gdf_cta['Line_Colors'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d98a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv(os.path.join(DATA_DIR, 'sales_data.csv'))\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f1e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIVERSE_DATA_ID = 'nj4t-kc8j'\n",
    "UNIVERSE_API_URL = f'https://datacatalog.cookcountyil.gov/resource/{UNIVERSE_DATA_ID}.csv'\n",
    "TEXT_FILE = os.path.join(INTERIM_DIR, 'universe_pin.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084dd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean TEXT_FILE by removing lines that contain \"None,None\" and trimming empty/trailing spaces\n",
    "if os.path.exists(TEXT_FILE):\n",
    "    with open(TEXT_FILE, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    before = len(lines)\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        if 'None,None' in s:\n",
    "            continue\n",
    "        cleaned.append(s)\n",
    "\n",
    "    with open(TEXT_FILE, 'w', encoding='utf-8') as f:\n",
    "        for ln in cleaned:\n",
    "            f.write(f\"{ln}\\n\")\n",
    "\n",
    "    print(f\"Cleaned {TEXT_FILE}: {before} -> {len(cleaned)} lines\")\n",
    "else:\n",
    "    print(f\"File not found: {TEXT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec30008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use existing cleaned lines if available, otherwise read from TEXT_FILE\n",
    "if 'cleaned' in globals():\n",
    "    src_lines = cleaned\n",
    "else:\n",
    "    with open(TEXT_FILE, 'r', encoding='utf-8') as f:\n",
    "        src_lines = [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "unique_pin10 = set()\n",
    "for ln in src_lines:\n",
    "    # skip header or empty lines\n",
    "    if not ln or ln.lower().startswith('pin10'):\n",
    "        continue\n",
    "    parts = ln.split(',')\n",
    "    if not parts:\n",
    "        continue\n",
    "    pin_raw = parts[0].strip()\n",
    "    if not pin_raw or pin_raw.lower() == 'none':\n",
    "        continue\n",
    "    # normalize trailing .0 (e.g. \"2503106015.0\" -> \"2503106015\")\n",
    "    if pin_raw.endswith('.0'):\n",
    "        pin = pin_raw[:-2]\n",
    "    else:\n",
    "        pin = pin_raw\n",
    "    unique_pin10.add(pin)\n",
    "\n",
    "# result available as `unique_pin10`\n",
    "print(\"Unique pin10 count:\", len(unique_pin10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d45abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['pin10'] = df_sales['pin'].astype(str).str[:10]\n",
    "all_pins = df_sales['pin10'].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pins_to_check = all_pins that are not present in unique_pin10 (preserve original order)\n",
    "pins_to_check = [p for p in all_pins if p not in unique_pin10]\n",
    "\n",
    "print(f\"Total all_pins: {len(all_pins)}\")\n",
    "print(f\"Pins already found (unique_pin10): {len(unique_pin10)}\")\n",
    "print(f\"Missing pins_to_check count: {len(pins_to_check)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINS_TO_CHECK_FILE = os.path.join(INTERIM_DIR, 'pins_to_check.txt')\n",
    "# # write one pin per line\n",
    "# with open(PINS_TO_CHECK_FILE, 'w', encoding='utf-8') as fh:\n",
    "#     for pin in pins_to_check:\n",
    "#         fh.write(f\"{pin}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pin(pin10):\n",
    "    params = {\n",
    "        '$limit': 1,\n",
    "        '$select': 'pin10, lon, lat',\n",
    "        '$where': f\"pin10 = '{pin10}'\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(UNIVERSE_API_URL, params=params, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        df = pd.read_csv(io.StringIO(r.text))\n",
    "        if not df.empty:\n",
    "            row = df.iloc[0]\n",
    "            return {'pin10': str(row.get('pin10')), 'lon': row.get('lon'), 'lat': row.get('lat')}\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for each_pin in pins_to_check:\n",
    "    result = fetch_pin(each_pin)\n",
    "    if result:\n",
    "        with open(TEXT_FILE, 'a', encoding='utf-8') as fh:\n",
    "            fh.write(f\"{result['pin10']},{result['lon']},{result['lat']}\\n\")\n",
    "    pins_to_check.remove(each_pin)\n",
    "    if random.randint(0, 30) == 0:\n",
    "        os.remove(PINS_TO_CHECK_FILE)\n",
    "        with open(PINS_TO_CHECK_FILE, 'w', encoding='utf-8') as fh:\n",
    "            for pin in pins_to_check:\n",
    "                fh.write(f\"{pin}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d474c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/interim/universe_pin.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "CSV_FILE = os.path.join(INTERIM_DIR, 'universe_pin.csv')\n",
    "shutil.copy(TEXT_FILE, CSV_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
